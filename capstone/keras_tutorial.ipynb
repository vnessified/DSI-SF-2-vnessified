{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import the necessary packages\n",
    "from keras.preprocessing import image as image_utils\n",
    "from imagenet_utils import decode_predictions\n",
    "from imagenet_utils import preprocess_input\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import colors\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_dir = '/Users/VanessaG/Desktop/pizza_class_data/train/'\n",
    "validation_data_dir = '/Users/VanessaG/Desktop/pizza_class_data/validation'\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "nb_epoch = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# Because you're using tensorflow you have to put the \"depth\" as the 3rd dimension.\n",
    "# Apparently for theano the depth comes first like in tutorial (3, 150, 150)\n",
    "# and in tensorflow it comes last like (150, 150, 3)\n",
    "model.add(Convolution2D(32, 3, 3, input_shape=(img_width, img_height, 3)))\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 800 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2000/2000 [==============================] - 82s - loss: 0.6828 - acc: 0.5670 - val_loss: 0.6194 - val_acc: 0.6700\n",
      "Epoch 2/50\n",
      "2000/2000 [==============================] - 79s - loss: 0.6339 - acc: 0.6540 - val_loss: 0.6113 - val_acc: 0.6325\n",
      "Epoch 3/50\n",
      "2000/2000 [==============================] - 80s - loss: 0.6017 - acc: 0.6885 - val_loss: 0.6596 - val_acc: 0.5675\n",
      "Epoch 4/50\n",
      "2000/2000 [==============================] - 78s - loss: 0.6032 - acc: 0.6965 - val_loss: 0.6497 - val_acc: 0.5887\n",
      "Epoch 5/50\n",
      "2000/2000 [==============================] - 79s - loss: 0.5918 - acc: 0.7000 - val_loss: 0.5221 - val_acc: 0.7325\n",
      "Epoch 6/50\n",
      "2000/2000 [==============================] - 78s - loss: 0.5547 - acc: 0.7145 - val_loss: 0.5147 - val_acc: 0.7200\n",
      "Epoch 7/50\n",
      "2000/2000 [==============================] - 78s - loss: 0.5237 - acc: 0.7435 - val_loss: 0.4807 - val_acc: 0.7650\n",
      "Epoch 8/50\n",
      "2000/2000 [==============================] - 77s - loss: 0.5384 - acc: 0.7440 - val_loss: 0.5481 - val_acc: 0.7475\n",
      "Epoch 9/50\n",
      "2000/2000 [==============================] - 77s - loss: 0.5218 - acc: 0.7485 - val_loss: 0.4595 - val_acc: 0.7900\n",
      "Epoch 10/50\n",
      "2000/2000 [==============================] - 77s - loss: 0.5171 - acc: 0.7460 - val_loss: 0.4530 - val_acc: 0.7837\n",
      "Epoch 11/50\n",
      "2000/2000 [==============================] - 76s - loss: 0.5103 - acc: 0.7560 - val_loss: 0.5399 - val_acc: 0.7538\n",
      "Epoch 12/50\n",
      "2000/2000 [==============================] - 78s - loss: 0.4996 - acc: 0.7760 - val_loss: 0.4983 - val_acc: 0.7662\n",
      "Epoch 13/50\n",
      "2000/2000 [==============================] - 76s - loss: 0.4867 - acc: 0.7930 - val_loss: 0.4737 - val_acc: 0.7738\n",
      "Epoch 14/50\n",
      "2000/2000 [==============================] - 76s - loss: 0.4941 - acc: 0.7635 - val_loss: 0.4260 - val_acc: 0.8037\n",
      "Epoch 15/50\n",
      "2000/2000 [==============================] - 76s - loss: 0.4646 - acc: 0.7835 - val_loss: 1.0656 - val_acc: 0.5363\n",
      "Epoch 16/50\n",
      "2000/2000 [==============================] - 76s - loss: 0.4655 - acc: 0.7965 - val_loss: 0.4330 - val_acc: 0.7900\n",
      "Epoch 17/50\n",
      "2000/2000 [==============================] - 76s - loss: 0.4628 - acc: 0.8020 - val_loss: 0.4745 - val_acc: 0.7875\n",
      "Epoch 18/50\n",
      "2000/2000 [==============================] - 76s - loss: 0.4530 - acc: 0.8020 - val_loss: 0.7086 - val_acc: 0.7000\n",
      "Epoch 19/50\n",
      "2000/2000 [==============================] - 79s - loss: 0.4406 - acc: 0.8075 - val_loss: 0.4122 - val_acc: 0.8063\n",
      "Epoch 20/50\n",
      "2000/2000 [==============================] - 78s - loss: 0.4513 - acc: 0.8015 - val_loss: 0.4098 - val_acc: 0.8100\n",
      "Epoch 21/50\n",
      "2000/2000 [==============================] - 81s - loss: 0.4358 - acc: 0.8060 - val_loss: 0.7381 - val_acc: 0.6875\n",
      "Epoch 22/50\n",
      "2000/2000 [==============================] - 79s - loss: 0.4428 - acc: 0.8050 - val_loss: 0.4838 - val_acc: 0.7850\n",
      "Epoch 23/50\n",
      "2000/2000 [==============================] - 79s - loss: 0.4257 - acc: 0.8180 - val_loss: 0.4062 - val_acc: 0.8163\n",
      "Epoch 24/50\n",
      "2000/2000 [==============================] - 77s - loss: 0.4285 - acc: 0.8165 - val_loss: 0.4069 - val_acc: 0.8313\n",
      "Epoch 25/50\n",
      "2000/2000 [==============================] - 76s - loss: 0.4259 - acc: 0.8095 - val_loss: 0.4202 - val_acc: 0.8200\n",
      "Epoch 26/50\n",
      "2000/2000 [==============================] - 78s - loss: 0.4027 - acc: 0.8275 - val_loss: 0.5426 - val_acc: 0.7238\n",
      "Epoch 27/50\n",
      "2000/2000 [==============================] - 76s - loss: 0.4128 - acc: 0.8235 - val_loss: 0.4771 - val_acc: 0.7887\n",
      "Epoch 28/50\n",
      "2000/2000 [==============================] - 77s - loss: 0.4062 - acc: 0.8330 - val_loss: 0.4409 - val_acc: 0.8000\n",
      "Epoch 29/50\n",
      "2000/2000 [==============================] - 80s - loss: 0.4122 - acc: 0.8095 - val_loss: 0.5196 - val_acc: 0.7662\n",
      "Epoch 30/50\n",
      "2000/2000 [==============================] - 77s - loss: 0.3987 - acc: 0.8275 - val_loss: 0.4363 - val_acc: 0.8025\n",
      "Epoch 31/50\n",
      "2000/2000 [==============================] - 76s - loss: 0.4031 - acc: 0.8290 - val_loss: 0.5667 - val_acc: 0.7475\n",
      "Epoch 32/50\n",
      "2000/2000 [==============================] - 76s - loss: 0.4066 - acc: 0.8290 - val_loss: 0.4170 - val_acc: 0.8013\n",
      "Epoch 33/50\n",
      "2000/2000 [==============================] - 81s - loss: 0.3865 - acc: 0.8370 - val_loss: 0.4635 - val_acc: 0.8100\n",
      "Epoch 34/50\n",
      "2000/2000 [==============================] - 80s - loss: 0.3910 - acc: 0.8270 - val_loss: 0.3974 - val_acc: 0.8400\n",
      "Epoch 35/50\n",
      "2000/2000 [==============================] - 75s - loss: 0.3781 - acc: 0.8450 - val_loss: 0.4190 - val_acc: 0.8137\n",
      "Epoch 36/50\n",
      "2000/2000 [==============================] - 79s - loss: 0.3900 - acc: 0.8415 - val_loss: 0.4141 - val_acc: 0.8013\n",
      "Epoch 37/50\n",
      "2000/2000 [==============================] - 77s - loss: 0.3754 - acc: 0.8515 - val_loss: 0.7393 - val_acc: 0.6887\n",
      "Epoch 38/50\n",
      "2000/2000 [==============================] - 77s - loss: 0.3741 - acc: 0.8370 - val_loss: 0.6271 - val_acc: 0.7475\n",
      "Epoch 39/50\n",
      "2000/2000 [==============================] - 84s - loss: 0.3712 - acc: 0.8405 - val_loss: 0.7130 - val_acc: 0.7512\n",
      "Epoch 40/50\n",
      "2000/2000 [==============================] - 79s - loss: 0.3727 - acc: 0.8460 - val_loss: 0.4493 - val_acc: 0.8337\n",
      "Epoch 41/50\n",
      "2000/2000 [==============================] - 80s - loss: 0.3722 - acc: 0.8450 - val_loss: 0.6633 - val_acc: 0.7700\n",
      "Epoch 42/50\n",
      "2000/2000 [==============================] - 80s - loss: 0.3661 - acc: 0.8440 - val_loss: 0.4446 - val_acc: 0.7875\n",
      "Epoch 43/50\n",
      "2000/2000 [==============================] - 80s - loss: 0.3713 - acc: 0.8475 - val_loss: 0.4292 - val_acc: 0.8275\n",
      "Epoch 44/50\n",
      "2000/2000 [==============================] - 80s - loss: 0.3570 - acc: 0.8480 - val_loss: 0.4520 - val_acc: 0.7812\n",
      "Epoch 45/50\n",
      "2000/2000 [==============================] - 82s - loss: 0.3341 - acc: 0.8650 - val_loss: 0.3963 - val_acc: 0.8200\n",
      "Epoch 46/50\n",
      "2000/2000 [==============================] - 83s - loss: 0.3521 - acc: 0.8440 - val_loss: 0.3727 - val_acc: 0.8462\n",
      "Epoch 47/50\n",
      "2000/2000 [==============================] - 83s - loss: 0.3679 - acc: 0.8465 - val_loss: 0.3928 - val_acc: 0.8475\n",
      "Epoch 48/50\n",
      "2000/2000 [==============================] - 78s - loss: 0.3590 - acc: 0.8560 - val_loss: 0.4265 - val_acc: 0.8450\n",
      "Epoch 49/50\n",
      "2000/2000 [==============================] - 76s - loss: 0.3392 - acc: 0.8540 - val_loss: 0.3874 - val_acc: 0.8237\n",
      "Epoch 50/50\n",
      "2000/2000 [==============================] - 75s - loss: 0.3468 - acc: 0.8605 - val_loss: 0.3727 - val_acc: 0.8525\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11dfff950>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch=nb_train_samples,\n",
    "        nb_epoch=nb_epoch,\n",
    "        validation_data=validation_generator,\n",
    "        nb_val_samples=nb_validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.save_weights('/Users/VanessaG/Desktop/DSI-SF-2-vnessified/capstone/keras_pizza_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.DirectoryIterator at 0x11e06f7d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Error when checking : data should be a Numpy array, or list/dict of Numpy arrays. Found: <keras.preprocessing.image.DirectoryIterator object at 0x11e06f7d0>...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-a2e5d10bb343>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/VanessaG/anaconda/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/VanessaG/anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         x = standardize_input_data(x, self.input_names,\n\u001b[1;32m   1160\u001b[0m                                    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m                                    check_batch_dim=False)\n\u001b[0m\u001b[1;32m   1162\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/VanessaG/anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_dim, exception_prefix)\u001b[0m\n\u001b[1;32m     68\u001b[0m                             \u001b[0;34m': data should be a Numpy array, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                             \u001b[0;34m'or list/dict of Numpy arrays. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                             'Found: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;31m# case: model expects multiple inputs but only received\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Error when checking : data should be a Numpy array, or list/dict of Numpy arrays. Found: <keras.preprocessing.image.DirectoryIterator object at 0x11e06f7d0>..."
     ]
    }
   ],
   "source": [
    "model.predict(train_generator, validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Error when checking model input: data should be a Numpy array, or list/dict of Numpy arrays. Found: <keras.preprocessing.image.DirectoryIterator object at 0x11e06f7d0>...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-12cedf56094d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.33\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/VanessaG/anaconda/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m                               sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/Users/VanessaG/anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m   1032\u001b[0m                                                            \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m                                                            \u001b[0mcheck_batch_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m                                                            batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1035\u001b[0m         \u001b[0;31m# prepare validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/VanessaG/anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_dim, batch_size)\u001b[0m\n\u001b[1;32m    959\u001b[0m                                    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m                                    \u001b[0mcheck_batch_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m                                    exception_prefix='model input')\n\u001b[0m\u001b[1;32m    962\u001b[0m         y = standardize_input_data(y, self.output_names,\n\u001b[1;32m    963\u001b[0m                                    \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/VanessaG/anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_dim, exception_prefix)\u001b[0m\n\u001b[1;32m     68\u001b[0m                             \u001b[0;34m': data should be a Numpy array, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                             \u001b[0;34m'or list/dict of Numpy arrays. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                             'Found: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;31m# case: model expects multiple inputs but only received\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Error when checking model input: data should be a Numpy array, or list/dict of Numpy arrays. Found: <keras.preprocessing.image.DirectoryIterator object at 0x11e06f7d0>..."
     ]
    }
   ],
   "source": [
    "model.fit(train_generator, validation_generator, validation_split=0.33, nb_epoch=10, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-5f7207f57814>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'history'"
     ]
    }
   ],
   "source": [
    "model.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
